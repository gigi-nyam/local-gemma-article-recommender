"""
ãƒãƒ«ãƒLLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼å¯¾å¿œã®è¨˜äº‹æ¨è–¦ãƒ­ã‚¸ãƒƒã‚¯
Ollama (ãƒ­ãƒ¼ã‚«ãƒ«)ã€Geminiã€OpenAI ã«å¯¾å¿œ
"""

import os
import requests
import json
import re
from typing import List, Dict, Optional
from pydantic import BaseModel
from dotenv import load_dotenv
from abc import ABC, abstractmethod

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
load_dotenv()


class ArticleRecommendation(BaseModel):
    """æ¨è–¦è¨˜äº‹ã®æ§‹é€ åŒ–å‡ºåŠ›"""
    article_id: int
    title: str
    reason: str
    clickbait_score: float  # 0-1ã®ã‚¹ã‚³ã‚¢
    read_satisfaction_score: Optional[float] = None  # èª­äº†å¾Œã®æº€è¶³åº¦äºˆæ¸¬
    continuation_intent_score: Optional[float] = None  # æ¬¡ã‚‚èª­ã¿ãŸããªã‚‹åº¦åˆã„
    is_serendipity: bool = False  # ã‚»ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ”ãƒ†ã‚£è¨˜äº‹ã‹ã©ã†ã‹
    serendipity_reason: Optional[str] = None  # ã‚»ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ”ãƒ†ã‚£é¸æŠç†ç”±


class RecommendationResult(BaseModel):
    """æ¨è–¦çµæœã®æ§‹é€ åŒ–å‡ºåŠ›"""
    recommendations: List[ArticleRecommendation]
    reasoning: str


class BaseLLMProvider(ABC):
    """LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®åŸºåº•ã‚¯ãƒ©ã‚¹"""
    
    @abstractmethod
    def generate(self, prompt: str) -> str:
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆ"""
        pass


class OllamaProvider(BaseLLMProvider):
    """Ollama API ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ (ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«)"""
    
    def __init__(self, model: str, base_url: str):
        self.model = model
        self.base_url = base_url
        
        # OllamaãŒåˆ©ç”¨å¯èƒ½ã‹ç¢ºèª
        try:
            response = requests.get(f"{base_url}/api/tags", timeout=5)
            if response.status_code == 200:
                models = [m['name'] for m in response.json().get('models', [])]
                if self.model not in models:
                    print(f"è­¦å‘Š: {self.model}ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
                    print(f"å®Ÿè¡Œã—ã¦ãã ã•ã„: ollama pull {self.model}")
            else:
                print(f"è­¦å‘Š: Ollama APIã«æ¥ç¶šã§ãã¾ã›ã‚“({base_url})")
        except Exception as e:
            print(f"Ollamaã®ç¢ºèªã«å¤±æ•—: {e}")
    
    def generate(self, prompt: str, timeout: int = 180) -> str:
        url = f"{self.base_url}/api/generate"
        
        payload = {
            "model": self.model,
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": 0.7,
                "num_predict": 1000
            }
        }
        
        response = requests.post(url, json=payload, timeout=timeout)
        
        if response.status_code != 200:
            raise RuntimeError(f"Ollama API ã‚¨ãƒ©ãƒ¼: {response.status_code} - {response.text}")
        
        result = response.json()
        return result.get('response', '')


class GeminiProvider(BaseLLMProvider):
    """Google Gemini API ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼"""

    def __init__(self, api_key: str, model: str = "gemini-3-pro-preview"):
        self.api_key = api_key
        self.model = model
        
        # google-genai (æ–°ã—ã„SDK) ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¨åˆæœŸåŒ–
        try:
            from google import genai
            self.client = genai.Client(api_key=api_key)
            print(f"âœ“ Gemini APIæ¥ç¶šæˆåŠŸ (ãƒ¢ãƒ‡ãƒ«: {model}) [google-genai SDK]")
        except ImportError:
            raise ImportError("google-genaiãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒå¿…è¦ã§ã™: pip install google-genai")
        except Exception as e:
            print(f"è­¦å‘Š: Gemini APIåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    def generate(self, prompt: str, timeout: int = 180) -> str:
        try:
            from google.genai import types
            
            # ç’°å¢ƒå¤‰æ•°ã§thinking_levelã‚’æŒ‡å®šå¯èƒ½ã«ã™ã‚‹
            # GEMINI_THINKING_LEVEL=low/high ã§åˆ¶å¾¡ï¼ˆGemini 3 Proï¼‰
            thinking_level_env = os.getenv("GEMINI_THINKING_LEVEL", "").lower()
            thinking_level = None
            if thinking_level_env in ["low", "high"]:
                thinking_level = thinking_level_env
            
            # GenerateContentConfigã®è¨­å®š
            if thinking_level:
                config = types.GenerateContentConfig(
                    temperature=0.7,
                    max_output_tokens=4000,
                    thinking_config=types.ThinkingConfig(thinking_level=thinking_level)
                )
                print(f"  ğŸ’­ thinking_level={thinking_level} ã‚’é©ç”¨ã—ã¾ã—ãŸ")
            else:
                config = types.GenerateContentConfig(
                    temperature=0.7,
                    max_output_tokens=4000
                )
                if thinking_level_env:
                    print(f"  â„¹ï¸ GEMINI_THINKING_LEVEL={thinking_level_env} (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå‹•ä½œ)")
                else:
                    print(f"  â„¹ï¸ thinking_level æœªè¨­å®šï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå‹•ä½œï¼‰")
            
            response = self.client.models.generate_content(
                model=self.model,
                contents=prompt,
                config=config
            )
            
            # response.text ã‚’ä½¿ç”¨ï¼ˆgoogle-genai ã§ã¯å®‰å…¨ã«ä½¿ç”¨å¯èƒ½ï¼‰
            return response.text
        except Exception as e:
            raise RuntimeError(f"Gemini API ã‚¨ãƒ©ãƒ¼: {e}")


class OpenAIProvider(BaseLLMProvider):
    """OpenAI API ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼"""
    
    def __init__(self, api_key: str, model: str = "gpt-4o"):
        self.api_key = api_key
        self.model = model
        
        try:
            from openai import OpenAI
            self.client = OpenAI(api_key=api_key)
            print(f"âœ“ OpenAI APIæ¥ç¶šæˆåŠŸ (ãƒ¢ãƒ‡ãƒ«: {model})")
        except ImportError:
            raise ImportError("openaiãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒå¿…è¦ã§ã™: pip install openai")
        except Exception as e:
            print(f"è­¦å‘Š: OpenAI APIåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    def generate(self, prompt: str, timeout: int = 180) -> str:
        try:
            # GPT-5ç³»ã§ã¯ max_completion_tokensã€GPT-4ç³»ä»¥å‰ã§ã¯ max_tokens ã‚’ä½¿ç”¨
            params = {
                "model": self.model,
                "messages": [
                    {"role": "system", "content": "ã‚ãªãŸã¯è¨˜äº‹æ¨è–¦ã®å°‚é–€å®¶ã§ã™ã€‚"},
                    {"role": "user", "content": prompt}
                ]
            }
            
            # ãƒ¢ãƒ‡ãƒ«åã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’åˆ‡ã‚Šæ›¿ãˆ
            if self.model.startswith("gpt-5") or self.model.startswith("o1") or self.model.startswith("o3"):
                params["max_completion_tokens"] = 1000
                # GPT-5ç³»ã¯temperatureã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤(1.0)ã®ã¿ã‚µãƒãƒ¼ãƒˆ
            else:
                params["max_tokens"] = 1000
                params["temperature"] = 0.7
            
            response = self.client.chat.completions.create(**params)
            return response.choices[0].message.content
        except Exception as e:
            raise RuntimeError(f"OpenAI API ã‚¨ãƒ©ãƒ¼: {e}")


class LocalGemmaRecommender:
    """ãƒãƒ«ãƒLLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼å¯¾å¿œã®è¨˜äº‹æ¨è–¦ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(
        self, 
        provider: Optional[str] = None,
        model: Optional[str] = None,
        api_key: Optional[str] = None,
        base_url: Optional[str] = None
    ):
        """
        åˆæœŸåŒ–
        
        Args:
            provider: LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ ("ollama", "gemini", "openai")ã€‚Noneã®å ´åˆã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
            model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«åã€‚Noneã®å ´åˆã¯ç’°å¢ƒå¤‰æ•°ã¾ãŸã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨
            api_key: APIã‚­ãƒ¼ã€‚Noneã®å ´åˆã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
            base_url: Ollama APIã®ãƒ™ãƒ¼ã‚¹URL (Ollamaã®å ´åˆã®ã¿)
        """
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’å–å¾—
        provider = provider or os.getenv("LLM_PROVIDER", "ollama")
        
        self.provider_name = provider
        
        # ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã«å¿œã˜ã¦LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–
        if provider == "ollama":
            model = model or os.getenv("OLLAMA_MODEL", "gemma3:4b")
            base_url = base_url or os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
            self.llm_provider = OllamaProvider(model=model, base_url=base_url)
            print(f"âœ“ Ollamaãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’ä½¿ç”¨ (ãƒ¢ãƒ‡ãƒ«: {model})")
            
        elif provider == "gemini":
            api_key = api_key or os.getenv("GEMINI_API_KEY")
            if not api_key:
                raise ValueError("GEMINI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            model = model or os.getenv("GEMINI_MODEL", "gemini-3-pro-preview")
            self.llm_provider = GeminiProvider(api_key=api_key, model=model)
            print(f"âœ“ Geminiãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’ä½¿ç”¨ (ãƒ¢ãƒ‡ãƒ«: {model})")
            
        elif provider == "openai":
            api_key = api_key or os.getenv("OPENAI_API_KEY")
            if not api_key:
                raise ValueError("OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            model = model or os.getenv("OPENAI_MODEL", "gpt-5.1")
            self.llm_provider = OpenAIProvider(api_key=api_key, model=model)
            print(f"âœ“ OpenAIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’ä½¿ç”¨ (ãƒ¢ãƒ‡ãƒ«: {model})")
            
        else:
            raise ValueError(f"æœªå¯¾å¿œã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: {provider}")
    
    def recommend_articles(
        self,
        user_query: str,
        candidate_articles: List[Dict],
        top_k: int = 3
    ) -> RecommendationResult:
        """
        å€™è£œè¨˜äº‹ã‹ã‚‰ã€Œã¤ã„ã‚¯ãƒªãƒƒã‚¯ã—ãŸããªã‚‹ã€è¨˜äº‹(top_k-2ä»¶)ã¨
        ã‚»ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ”ãƒ†ã‚£è¨˜äº‹(2ä»¶)ã‚’é¸æŠ
        
        Args:
            user_query: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ¤œç´¢ã‚¯ã‚¨ãƒª
            candidate_articles: å€™è£œè¨˜äº‹ã®ãƒªã‚¹ãƒˆ
            top_k: æ¨è–¦ã™ã‚‹è¨˜äº‹æ•°ï¼ˆã‚¯ãƒªãƒƒã‚¯èª˜å¼•: top_k-2ä»¶ + ã‚»ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ”ãƒ†ã‚£: 2ä»¶ï¼‰
            
        Returns:
            æ¨è–¦çµæœ
        """
        # å€™è£œè¨˜äº‹ã‚’çµã‚Šè¾¼ã‚€ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒé•·ã™ãã‚‹ãŸã‚ï¼‰
        limited_candidates = candidate_articles[:min(10, len(candidate_articles))]
        
        # ã‚¯ãƒªãƒƒã‚¯èª˜å¼•è¨˜äº‹ã®ä»¶æ•°ï¼ˆæœ€ä½1ä»¶ï¼‰
        clickbait_count = max(1, top_k - 2)
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰ï¼ˆã‚¯ãƒªãƒƒã‚¯èª˜å¼•è¨˜äº‹ç”¨ï¼‰
        prompt = self._build_prompt(user_query, limited_candidates, clickbait_count)
        
        # LLM APIã§æ¨è«–ã‚’å®Ÿè¡Œï¼ˆã‚¯ãƒªãƒƒã‚¯èª˜å¼•è¨˜äº‹ï¼‰
        try:
            response_text = self.llm_provider.generate(prompt)
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹
            clickbait_result = self._parse_response(response_text, limited_candidates)
            
            # é¸æŠã•ã‚ŒãŸã‚¯ãƒªãƒƒã‚¯èª˜å¼•è¨˜äº‹ã®IDã‚’å–å¾—
            selected_ids = [rec.article_id for rec in clickbait_result.recommendations]
            
            # ã‚»ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ”ãƒ†ã‚£è¨˜äº‹ã‚’é¸æŠ
            serendipity_result = self._recommend_serendipity_articles(
                user_query=user_query,
                candidate_articles=limited_candidates,
                exclude_ids=selected_ids,
                count=2
            )
            
            # çµæœã‚’çµ±åˆ
            all_recommendations = clickbait_result.recommendations + serendipity_result.recommendations
            
            combined_reasoning = (
                f"ã€ã‚¯ãƒªãƒƒã‚¯èª˜å¼•è¨˜äº‹ã€‘{clickbait_result.reasoning}\n"
                f"ã€ã‚»ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ”ãƒ†ã‚£è¨˜äº‹ã€‘{serendipity_result.reasoning}"
            )
            
            return RecommendationResult(
                recommendations=all_recommendations,
                reasoning=combined_reasoning
            )
            
        except Exception as e:
            print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æœ€åˆã®top_kä»¶ã‚’è¿”ã™
            return self._fallback_recommendation(limited_candidates, top_k)
    
    def _recommend_serendipity_articles(
        self,
        user_query: str,
        candidate_articles: List[Dict],
        exclude_ids: List[int],
        count: int = 2
    ) -> RecommendationResult:
        """
        ã‚»ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ”ãƒ†ã‚£æ€§ã®é«˜ã„è¨˜äº‹ã‚’é¸æŠ
        
        Args:
            user_query: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ¤œç´¢ã‚¯ã‚¨ãƒª
            candidate_articles: å€™è£œè¨˜äº‹ã®ãƒªã‚¹ãƒˆ
            exclude_ids: é™¤å¤–ã™ã‚‹è¨˜äº‹IDã®ãƒªã‚¹ãƒˆ
            count: é¸æŠã™ã‚‹è¨˜äº‹æ•°
            
        Returns:
            ã‚»ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ”ãƒ†ã‚£æ¨è–¦çµæœ
        """
        # é™¤å¤–ã—ãŸå€™è£œè¨˜äº‹ãƒªã‚¹ãƒˆã‚’ä½œæˆ
        filtered_candidates = [
            article for article in candidate_articles
            if article['id'] not in exclude_ids
        ]
        
        if len(filtered_candidates) == 0:
            return RecommendationResult(
                recommendations=[],
                reasoning="ã‚»ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ”ãƒ†ã‚£è¨˜äº‹ã®å€™è£œãŒã‚ã‚Šã¾ã›ã‚“"
            )
        
        # ã‚»ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ”ãƒ†ã‚£ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
        prompt = self._build_serendipity_prompt(user_query, filtered_candidates, count)
        
        try:
            response_text = self.llm_provider.generate(prompt)
            result = self._parse_serendipity_response(response_text, filtered_candidates)
            return result
        except Exception as e:
            print(f"ã‚»ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ”ãƒ†ã‚£è¨˜äº‹é¸æŠã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
            return RecommendationResult(
                recommendations=[],
                reasoning="ã‚»ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ”ãƒ†ã‚£è¨˜äº‹ã®é¸æŠã«å¤±æ•—ã—ã¾ã—ãŸ"
            )
    
    def _build_serendipity_prompt(
        self,
        user_query: str,
        candidate_articles: List[Dict],
        count: int
    ) -> str:
        """ã‚»ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ”ãƒ†ã‚£è¨˜äº‹é¸æŠç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰"""
        articles_text = "\n".join([
            f"ID:{article['id']} [{article['summary']}] {article['title']}"
            for article in candidate_articles
        ])
        
        return f"""ã‚ãªãŸã¯è¨˜äº‹æ¨è–¦ã®å°‚é–€å®¶ã§ã™ã€‚

ã€ã‚¿ã‚¹ã‚¯èª¬æ˜ã€‘
ã‚»ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ”ãƒ†ã‚£ã¨ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¨ã£ã¦ã€ŒäºˆæœŸã›ã¬ã€ã‹ã¤ã€Œé–¢é€£æ€§ã®ã‚ã‚‹ã€ç™ºè¦‹ã®ã“ã¨ã§ã™ã€‚

- äºˆæœŸã›ã¬ï¼ˆUnexpectednessï¼‰ï¼šãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä»Šèª­ã‚“ã è¨˜äº‹ã‹ã‚‰ã¯ã€ç›´æ¥æ¨å¥¨ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒä½ã„ã‚¢ã‚¤ãƒ†ãƒ ã§ã‚ã‚‹ã“ã¨ã‚’æ„å‘³ã—ã¾ã™ã€‚
- é–¢é€£æ€§ï¼ˆRelevanceï¼‰ï¼šãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä»Šèª­ã‚“ã è¨˜äº‹ã¸ã®ï¼ˆæš—é»™çš„ãªï¼‰èˆˆå‘³ã«å¯†æ¥ã«é–¢é€£ã—ã¦ã„ã‚‹ã“ã¨ã‚’æ„å‘³ã—ã¾ã™ã€‚

ã‚ã‚‹ã‚¢ã‚¤ãƒ†ãƒ ãŒã‚»ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ”ãƒ†ã‚£ã§ã‚ã‚‹ãŸã‚ã«ã¯ã€ã“ã‚Œã‚‰ä¸¡æ–¹ã®æ¡ä»¶ã‚’æº€ãŸã—ã¦ã„ã‚‹å¿…è¦
ãŒã‚ã‚Šã¾ã™ã€‚
å¿…ãš{count}ä»¶ã®è¨˜äº‹ã‚’é¸æŠã—ã€å„è¨˜äº‹ã«ã¤ã„ã¦ã‚»ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ”ãƒ†ã‚£é¸æŠç†ç”±ã‚’æ˜ç¢ºã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚

ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒèª­ã‚“ã è¨˜äº‹: ã€Œ{user_query}ã€

å€™è£œè¨˜äº‹:
{articles_text}

ä»¥ä¸‹ã®æœ‰åŠ¹ãªJSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„:
{{
  "recommendations": [
    {{
      "article_id": 2,
      "title": "è¨˜äº‹ã®è¦ç´„",
      "serendipity_reason": "ã‚»ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ”ãƒ†ã‚£é¸æŠç†ç”±ï¼ˆäºˆæœŸã›ã¬ç‚¹ã¨é–¢é€£æ€§ã‚’èª¬æ˜ï¼‰",
      "unexpectedness_score": 0.85,
      "relevance_score": 0.75
    }}
  ],
  "reasoning": "å…¨ä½“çš„ãªã‚»ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ”ãƒ†ã‚£é¸æŠæ–¹é‡"
}}

å¿…ãšæœ‰åŠ¹ãªJSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚JSONä»¥å¤–ã®ãƒ†ã‚­ã‚¹ãƒˆã¯å‡ºåŠ›ã—ãªã„ã§ãã ã•ã„ã€‚"""
    
    def _parse_serendipity_response(
        self,
        response_text: str,
        candidate_articles: List[Dict]
    ) -> RecommendationResult:
        """ã‚»ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ”ãƒ†ã‚£ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹"""
        try:
            # JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡º
            json_match = re.search(r'```json\s*\n(.+?)\n```', response_text, re.DOTALL)
            if json_match:
                json_text = json_match.group(1)
            else:
                json_match = re.search(r'\{.*"recommendations".*\}', response_text, re.DOTALL)
                if json_match:
                    json_text = json_match.group(0)
                else:
                    json_text = response_text.strip()
            
            json_text = json_text.strip()
            
            if not json_text.endswith('}'):
                last_brace = json_text.rfind('}')
                if last_brace > 0:
                    json_text = json_text[:last_brace + 1]
            
            json_text = re.sub(r'\}\s*\n\s*\{', '},\n{', json_text)
            
            data = json.loads(json_text)
            
            recommendations = []
            for rec in data.get('recommendations', []):
                article_id = rec.get('article_id')
                article = next((a for a in candidate_articles if a['id'] == article_id), None)
                
                if article:
                    # ã‚»ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ”ãƒ†ã‚£ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆäºˆæœŸã›ã¬åº¦ã¨é–¢é€£æ€§ã®èª¿å’Œå¹³å‡ï¼‰
                    unexpectedness = rec.get('unexpectedness_score', 0.5)
                    relevance = rec.get('relevance_score', 0.5)
                    serendipity_score = 2 * unexpectedness * relevance / (unexpectedness + relevance) if (unexpectedness + relevance) > 0 else 0
                    
                    recommendations.append(ArticleRecommendation(
                        article_id=article_id,
                        title=rec.get('title', article['title']),
                        reason=rec.get('serendipity_reason', ''),
                        clickbait_score=serendipity_score,
                        is_serendipity=True,
                        serendipity_reason=rec.get('serendipity_reason', '')
                    ))
            
            return RecommendationResult(
                recommendations=recommendations,
                reasoning=data.get('reasoning', '')
            )
            
        except Exception as e:
            print(f"ã‚»ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ”ãƒ†ã‚£ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—: {e}")
            print(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹å†…å®¹ï¼ˆæœ€åˆã®500æ–‡å­—ï¼‰: {response_text[:500]}")
            raise
    
    def _build_prompt(
        self,
        user_query: str,
        candidate_articles: List[Dict],
        top_k: int
    ) -> str:
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰ï¼ˆPROMPT_TYPEã«å¿œã˜ã¦åˆ‡ã‚Šæ›¿ãˆï¼‰"""
        articles_text = "\n".join([
            f"ID:{article['id']} [{article['summary']}] {article['title']}"
            for article in candidate_articles
        ])
        
        prompt_type = os.getenv("PROMPT_TYPE", "satisfaction").lower()
        
        if prompt_type == "clickbait":
            # ã‚¯ãƒªãƒƒã‚¯èª˜å¼•åº¦é‡è¦–ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            return f"""ã‚ãªãŸã¯è¨˜äº‹æ¨è–¦ã®å°‚é–€å®¶ã§ã™ã€‚

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ãƒª: ã€Œ{user_query}ã€

ä»¥ä¸‹ã®å€™è£œè¨˜äº‹ã‹ã‚‰ã€Œã¤ã„ã‚¯ãƒªãƒƒã‚¯ã—ãŸããªã‚‹ã€è¨˜äº‹ã‚’{top_k}ä»¶é¸ã‚“ã§ãã ã•ã„ã€‚
ãŸã ã—ã€å…¥åŠ›ã¨ä¼¼ãŸè¨˜äº‹ã‚„ä¸€èˆ¬çš„ãªäººæ°—è¨˜äº‹ã¯é¿ã‘ã¦ã€ã“ã®è¨˜äº‹ã‚’èª­ã‚“ã å¾Œã§æ°—ã«ãªã‚Šãã†ãªè¨˜äº‹ã«é™ã£ã¦ãã ã•ã„ã€‚

å€™è£œè¨˜äº‹:
{articles_text}

ä»¥ä¸‹ã®æœ‰åŠ¹ãªJSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚
é‡è¦: titleã«ã¯è¨˜äº‹ã®ç°¡æ½”ãªè¦ç´„ã‚’æ›¸ã„ã¦ãã ã•ã„ï¼ˆå…ƒã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’ãã®ã¾ã¾ã‚³ãƒ”ãƒ¼ã—ãªã„ï¼‰ã€‚
é‡è¦: æ–‡å­—åˆ—å€¤ã¯å¿…ãšãƒ€ãƒ–ãƒ«ã‚¯ã‚©ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆ"ï¼‰ã§å›²ã‚“ã§ãã ã•ã„ã€‚

{{
  "recommendations": [
    {{"article_id": 2, "title": "è¨˜äº‹ã®è¦ç´„", "reason": "é¸æŠç†ç”±", "clickbait_score": 0.85}}
  ],
  "reasoning": "é¸æŠæ–¹é‡"
}}

å¿…ãšæœ‰åŠ¹ãªJSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚JSONä»¥å¤–ã®ãƒ†ã‚­ã‚¹ãƒˆã¯å‡ºåŠ›ã—ãªã„ã§ãã ã•ã„ã€‚"""
        else:
            # èª­äº†æº€è¶³åº¦é‡è¦–ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
            return f"""ã‚ãªãŸã¯è¨˜äº‹æ¨è–¦ã®å°‚é–€å®¶ã§ã™ã€‚

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ãƒª: ã€Œ{user_query}ã€

ä»¥ä¸‹ã®å€™è£œè¨˜äº‹ã‹ã‚‰ã€èª­äº†å¾Œã«æº€è¶³åº¦ãŒé«˜ãã€æ¬¡ã‚‚èª­ã¿ãŸããªã‚‹è¨˜äº‹ã‚’{top_k}ä»¶é¸ã‚“ã§ãã ã•ã„ã€‚

è©•ä¾¡åŸºæº–:
1. clickbait_score: ã‚¯ãƒªãƒƒã‚¯ã—ãŸããªã‚‹åº¦åˆã„ï¼ˆ0-1ï¼‰
2. read_satisfaction_score: èª­äº†å¾Œã®æº€è¶³åº¦äºˆæ¸¬ï¼ˆ0-1ï¼‰
   - ã‚¿ã‚¤ãƒˆãƒ«ã¨å†…å®¹ã®ä¸€è‡´åº¦
   - æƒ…å ±ã®æ·±ã•ã¨è³ª
3. continuation_intent_score: æ¬¡ã‚‚èª­ã¿ãŸããªã‚‹åº¦åˆã„ï¼ˆ0-1ï¼‰
   - æ–°ãŸãªç–‘å•ã‚„èˆˆå‘³ã‚’å–šèµ·ã™ã‚‹ã‹
   - é–¢é€£ãƒˆãƒ”ãƒƒã‚¯ã¸ã®è‡ªç„¶ãªå°ç·š

å€™è£œè¨˜äº‹:
{articles_text}

JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„:
{{
  "recommendations": [
    {{
      "article_id": 2,
      "title": "è¨˜äº‹ã®è¦ç´„",
      "reason": "é¸æŠç†ç”±",
      "clickbait_score": 0.85,
      "read_satisfaction_score": 0.90,
      "continuation_intent_score": 0.88
    }}
  ],
  "reasoning": "é¸æŠæ–¹é‡"
}}
"""
    
    def _parse_response(
        self,
        response_text: str,
        candidate_articles: List[Dict]
    ) -> RecommendationResult:
        """ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹"""
        try:
            # JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡º
            json_match = re.search(r'```json\s*\n(.+?)\n```', response_text, re.DOTALL)
            if json_match:
                json_text = json_match.group(1)
            else:
                json_match = re.search(r'\{.*"recommendations".*\}', response_text, re.DOTALL)
                if json_match:
                    json_text = json_match.group(0)
                else:
                    # å…¨ä½“ã‚’JSONã¨ã—ã¦è©¦ã™
                    json_text = response_text.strip()
            
            # ä½™è¨ˆãªæ–‡å­—ã‚’å‰Šé™¤
            json_text = json_text.strip()
            
            # JSONå†…ã®å¼•ç”¨ç¬¦ã®å•é¡Œã‚’ä¿®æ­£ï¼ˆ"ãŒ"ã«ãªã£ã¦ã„ã‚‹å ´åˆãªã©ï¼‰
            # ä¸å®Œå…¨ãªJSONã‚’ä¿®æ­£
            if not json_text.endswith('}'):
                # æœ€å¾Œã®å®Œå…¨ãªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¾ã§åˆ‡ã‚Šå–ã‚‹
                last_brace = json_text.rfind('}')
                if last_brace > 0:
                    json_text = json_text[:last_brace + 1]
            
            # GemmaãŒé…åˆ—ã®è¦ç´ é–“ã®ã‚«ãƒ³ãƒã‚’çœç•¥ã™ã‚‹å•é¡Œã‚’ä¿®æ­£
            # ä¾‹: }{  â†’  },{  
            json_text = re.sub(r'\}\s*\n\s*\{', '},\n{', json_text)
            
            data = json.loads(json_text)
            
            # Pydanticãƒ¢ãƒ‡ãƒ«ã«å¤‰æ›
            recommendations = []
            for rec in data.get('recommendations', []):
                # è¨˜äº‹IDã«å¯¾å¿œã™ã‚‹å®Œå…¨ãªæƒ…å ±ã‚’å–å¾—
                article_id = rec.get('article_id')
                article = next((a for a in candidate_articles if a['id'] == article_id), None)
                
                if article:
                    recommendations.append(ArticleRecommendation(
                        article_id=article_id,
                        title=rec.get('title', article['title']),
                        reason=rec.get('reason', ''),
                        clickbait_score=rec.get('clickbait_score', 0.5),
                        read_satisfaction_score=rec.get('read_satisfaction_score'),
                        continuation_intent_score=rec.get('continuation_intent_score')
                    ))
            
            return RecommendationResult(
                recommendations=recommendations,
                reasoning=data.get('reasoning', '')
            )
                
        except Exception as e:
            print(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—: {e}")
            print(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹å†…å®¹ï¼ˆæœ€åˆã®500æ–‡å­—ï¼‰: {response_text[:500]}")
            raise
    
    def _fallback_recommendation(
        self,
        candidate_articles: List[Dict],
        top_k: int
    ) -> RecommendationResult:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¨è–¦"""
        recommendations = [
            ArticleRecommendation(
                article_id=article['id'],
                title=article['title'],
                reason="ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ¨è–¦",
                clickbait_score=0.5
            )
            for article in candidate_articles[:top_k]
        ]
        
        return RecommendationResult(
            recommendations=recommendations,
            reasoning="ã‚¨ãƒ©ãƒ¼ã®ãŸã‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ¨è–¦ã‚’ä½¿ç”¨"
        )


def demo_local_gemma_recommender():
    """ãƒãƒ«ãƒLLMæ¨è–¦ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
    from sample_articles import SAMPLE_ARTICLES
    
    print("=" * 60)
    print("ãƒãƒ«ãƒLLMè¨˜äº‹æ¨è–¦ãƒ‡ãƒ¢")
    print("=" * 60)
    print()
    
    # æ¨è–¦ã‚¨ãƒ³ã‚¸ãƒ³ã‚’åˆæœŸåŒ– (ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã¿)
    recommender = LocalGemmaRecommender()
    
    # ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª
    test_queries = [
        "å²©æ‰‹ã®ä½å®…åœ°è¿‘ãã§ã‚¯ãƒ2é ­ãŒé€£æ—¥æŸ¿ã®æœ¨ã«å‡ºæ²¡",
    ]
    
    for test_query in test_queries:
        print(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ãƒª: ã€Œ{test_query}ã€")
        print("-" * 60)
        print()
        
        # å€™è£œè¨˜äº‹
        candidate_articles = SAMPLE_ARTICLES
        
        print(f"å€™è£œè¨˜äº‹æ•°: {len(candidate_articles)}ä»¶ï¼ˆä¸Šä½10ä»¶ã«çµã‚Šè¾¼ã¿ï¼‰")
        top_k = int(os.getenv("LLM_RECOMMENDATION_TOP_K", "5"))
        clickbait_count = max(1, top_k - 2)
        prompt_type = os.getenv("PROMPT_TYPE", "satisfaction").lower()
        if prompt_type == "clickbait":
            print(f"{recommender.provider_name}ã§ã€Œã¤ã„ã‚¯ãƒªãƒƒã‚¯ã—ãŸããªã‚‹ã€è¨˜äº‹ã‚’{clickbait_count}ä»¶ + ã‚»ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ”ãƒ†ã‚£è¨˜äº‹2ä»¶é¸æŠä¸­...")
        else:
            print(f"{recommender.provider_name}ã§ã€Œèª­äº†æº€è¶³åº¦ã®é«˜ã„ã€è¨˜äº‹ã‚’{clickbait_count}ä»¶ + ã‚»ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ”ãƒ†ã‚£è¨˜äº‹2ä»¶é¸æŠä¸­...")
        print()
        
        # æ¨è–¦ã‚’å®Ÿè¡Œ
        import time
        start_time = time.time()
        
        result = recommender.recommend_articles(
            user_query=test_query,
            candidate_articles=candidate_articles,
            top_k=int(os.getenv("LLM_RECOMMENDATION_TOP_K", "5"))
        )
        
        elapsed_time = time.time() - start_time
        
        # çµæœã‚’è¡¨ç¤º
        print("ã€æ¨è–¦çµæœã€‘")
        print(f"é¸æŠæ–¹é‡: {result.reasoning}")
        print()
        
        # é€šå¸¸è¨˜äº‹ã¨ã‚»ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ”ãƒ†ã‚£è¨˜äº‹ã‚’åˆ†ã‘ã¦è¡¨ç¤º
        normal_recs = [rec for rec in result.recommendations if not rec.is_serendipity]
        serendipity_recs = [rec for rec in result.recommendations if rec.is_serendipity]
        
        if normal_recs:
            print("\n--- ã‚¯ãƒªãƒƒã‚¯èª˜å¼•è¨˜äº‹ ---")
            for i, rec in enumerate(normal_recs, 1):
                print(f"{i}. {rec.title}")
                print(f"   ã‚¯ãƒªãƒƒã‚¯èª˜å¼•åº¦: {rec.clickbait_score:.2f}")
                if rec.read_satisfaction_score is not None:
                    print(f"   èª­äº†æº€è¶³åº¦: {rec.read_satisfaction_score:.2f}")
                if rec.continuation_intent_score is not None:
                    print(f"   ç¶™ç¶šæ„å‘åº¦: {rec.continuation_intent_score:.2f}")
                print(f"   é¸æŠç†ç”±: {rec.reason}")
                print()
        
        if serendipity_recs:
            print("\n--- ã‚»ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ”ãƒ†ã‚£è¨˜äº‹ ---")
            for i, rec in enumerate(serendipity_recs, 1):
                print(f"{i}. {rec.title}")
                print(f"   ã‚»ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ”ãƒ†ã‚£ã‚¹ã‚³ã‚¢: {rec.clickbait_score:.2f}")
                print(f"   ã‚»ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ”ãƒ†ã‚£ç†ç”±: {rec.serendipity_reason}")
                print()
        
        print(f"å‡¦ç†æ™‚é–“: {elapsed_time:.2f}ç§’")
        print()
        print("=" * 60)
        print()
    
    return recommender


if __name__ == "__main__":
    demo_local_gemma_recommender()
